<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>HopKeep | Projects</title>
  <meta name="color-scheme" content="dark">
  <link rel="stylesheet" href="project.scss">
  {{> site_icons }}
</head>
<body>
  {{> topnav }}
  <section class="gradient page-header">
    <div class="heading-container">
      <h1>HopKeep</h1>
      <p>A machine learning app that enables the Hopscotch Project Curators to review 2700 projects per week.</p>
    </div>
    <br>
    <div class="center">
      <img src="/src/images/projects/hopkeep.png" alt="HopKeep Landing Page" width="800">
    </div>
  </section>
  <section>
    <div class="content-wrapper">
      <h1>The Project Landscape</h1>
      <p>One of the most difficult parts of any user content platform is selecting which content to feature. Hopscotch is no exception to this with picking
        the most fun and interesting coding projects made by kids. Without the ability to query the database directly, the only way to bulk-assess a
        project&rsquo;s quality was by its metadata, that is, its view statistics, creation time, draft age, and so on.</p>
      <p>As a part of my original <a href="/src/projects/hopscotch-tools.hbs">Hopscotch Tools</a> project, I added a feature to filter projects based on a predefined
        set of criteria. This was fairly effective at finding a few interesting projects (by filtering out spam). However, the challenge of scoring thousands
        of projects accurately <b><i>without looking at its code</i></b> still remained.</p>
      <p>So, I turned to machine learning in May 2024 as a next step.</p>
    </div>
    <div class="content-wrapper">
      <h1 class="icons-container">
        The Technological Backbone
        <div class="icons-row">
          <img src="/src/images/logos/python.svg" alt="Python Logo" width="44">
          <img src="/src/images/logos/sklearn.svg" alt="SciKit-Learn Logo" width="44">
          <img src="/src/images/logos/react.svg" alt="React Logo" width="44">
          <img src="/src/images/logos/typescript.svg" alt="TypeScript Logo" width="44">
          <img src="/src/images/logos/sass.svg" alt="Sass Logo" width="44">
          <img src="/src/images/logos/postgresql.svg" alt="PostgreSQL Logo" width="44">
          <img src="/src/images/logos/node.svg" alt="Node.js Logo" width="44">
        </div>
      </h1>
      <p>I began by evaluating what machine learning model would suit this task best. I needed the model to output a score based on various combinations of features,
        with some features expected to be significantly more important than others. I chose to use a Random Forest Regressor because of its ability to create partitions
        and identify feature importance.</p>
      <p>After experimenting with the model, I was able to effectively separate the data and capture complex patterns in the projects&rsquo; metadata. Ultimately, the model
        was able to account for 94% the variability in score for projects over a 6-month period.</p>
      <p>In addition to creating the model, I used Streamlit to create a playground for testing the model against new data and also built a custom interface that allowed
        <b><i>other team members</i></b> to add their own votes to projects! My custom interface is built with React and uses PostgreSQL to store the curation team&rsquo;s votes,
        enabling secondary review of potential featured projects for the first time.</p>
      <div class="center">
        <img src="/src/images/projects/hopkeep-s1.png" alt="Screenshot of Streamlit playground" width="640">
        <p class="caption">The Streamlit playground showing score and metadata stats</p>
      </div>
      <br>
    </div>
    <div class="content-wrapper">
      <h1>All About Efficiency</h1>
      <p>What started as a fun project to start learning how to train ML models turned out to have a far-reaching impact. To start, the model&rsquo;s ability to account for
        94% of variability between project metadata and quality gave us confidence that a majority of the scores would be representative of the actual data.</p>
      <p>But the true power came when I paired the ML model with a user-friendly front end. Being able to browse through the newest project feed with the <b><i>ML model
        directly accessible</i></b> enabled the curation team to spend <b>7x less time filtering</b> through projects in a single session.</p>
      <p>In addition to the time saved, we were able to significantly increase the number of projects we were actually able to feature. With HopKeep, the curation team
        is able to review over <b>2700 projects every week</b>, and despite this, we are able to <b>feature 5.2x as many projects</b> compared to manually looking for
        potential projects to feature with the static criteria filter used previously.</p>
      <p></p>
      <div class="center">
        <img src="/src/images/projects/hopkeep-s2.png" alt="Screenshot of the curation interface, showing projects in a grid with a side panel containing project info" width="640">
        <p class="caption">The curation interface showing the metadata and code scores of recent projects</p>
      </div>
      <br>
    </div>
  </section>
  {{> footer }}
</body>
</html>